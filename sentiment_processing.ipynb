{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871595db-29b9-46c5-ba8e-fe7f72eccc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import en_core_web_md\n",
    "\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623f69e4-4dff-41bd-82db-0c4c98df79ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Source</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-12</td>\n",
       "      <td>On the 9th Anniversary of the Philippines-Chin...</td>\n",
       "      <td>Nine years ago, an Arbitral Tribunal constitut...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2025-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>Secretary of State Marco Rubio Remarks to the ...</td>\n",
       "      <td>SECRETARY RUBIO: We had a great visit – great ...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2025-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>Secretary of State Marco Rubio Remarks to the ...</td>\n",
       "      <td>SECRETARY RUBIO:  You guys don’t look nearly a...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2025-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>Secretary Rubio’s Meeting with China’s Directo...</td>\n",
       "      <td>The below is attributable to Spokesperson Tamm...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2025-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Department Press Briefing – July 8, 2025</td>\n",
       "      <td>QUESTION: On – there was this press conference...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2025-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                              Title  \\\n",
       "0 2025-07-12  On the 9th Anniversary of the Philippines-Chin...   \n",
       "1 2025-07-11  Secretary of State Marco Rubio Remarks to the ...   \n",
       "2 2025-07-11  Secretary of State Marco Rubio Remarks to the ...   \n",
       "3 2025-07-11  Secretary Rubio’s Meeting with China’s Directo...   \n",
       "4 2025-07-08           Department Press Briefing – July 8, 2025   \n",
       "\n",
       "                                             Content Source    Month  \n",
       "0  Nine years ago, an Arbitral Tribunal constitut...    USA  2025-07  \n",
       "1  SECRETARY RUBIO: We had a great visit – great ...    USA  2025-07  \n",
       "2  SECRETARY RUBIO:  You guys don’t look nearly a...    USA  2025-07  \n",
       "3  The below is attributable to Spokesperson Tamm...    USA  2025-07  \n",
       "4  QUESTION: On – there was this press conference...    USA  2025-07  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data, treat Date as a string so that 0X does not turn into X for day\n",
    "usa_china_df = pd.read_csv('data/usa_china_text_data.csv', dtype = {'Date': str})\n",
    "usa_canada_df = pd.read_csv('data/usa_canada_text_data.csv', dtype = {'Date': str})\n",
    "china_canada_df = pd.read_csv('data/china_canada_text_data.csv', dtype = {'Date': str})\n",
    "\n",
    "#strip newline characters that were appearing\n",
    "china_canada_df['Source'] = china_canada_df['Source'].str.strip()\n",
    "\n",
    "#Drop NaNs that occurred\n",
    "usa_china_df = usa_china_df.dropna(subset=['Content'])\n",
    "usa_canada_df = usa_canada_df.dropna(subset=['Content'])\n",
    "china_canada_df = china_canada_df.dropna(subset=['Content'])\n",
    "\n",
    "#convert date to datetime format and add month column to calculate monthly sentiment\n",
    "usa_china_df['Date'] = pd.to_datetime(usa_china_df['Date'], format='%d%m%y')\n",
    "usa_china_df['Month'] = usa_china_df['Date'].dt.to_period('M')\n",
    "\n",
    "usa_canada_df['Date'] = pd.to_datetime(usa_canada_df['Date'], format='%d%m%y')\n",
    "usa_canada_df['Month'] = usa_canada_df['Date'].dt.to_period('M')\n",
    "\n",
    "#assign 28th of February since leap year 29th is not in datetime\n",
    "china_canada_df.loc[23, 'Date'] = '280225'\n",
    "china_canada_df['Date'] = pd.to_datetime(china_canada_df['Date'], format='%d%m%y')\n",
    "china_canada_df['Month'] = china_canada_df['Date'].dt.to_period('M')\n",
    "\n",
    "usa_china_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b563a0ee-8e87-4438-bcf4-6658466ebf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words used in USA-China relations by USA (TF-IDF):\n",
      "[('secretary', 3.416907265059992), ('china', 2.9557522350486427), ('question', 2.8475275588250026), ('rubio', 2.7323854873000655), ('going', 2.4388661932193862), ('iran', 2.1821677180160477), ('chinese', 2.062254299730788), ('states', 1.9919191770430558), ('bruce', 1.9853780313459912), ('president', 1.933671115844641)]\n",
      "\n",
      "Top ten words used in USA-China relations by China (TF-IDF):\n",
      "[('china', 13.400747944428133), ('relations', 5.805258088314767), ('xi', 5.004042084937861), ('president', 4.7723511757204085), ('cooperation', 4.749948910603949), ('states', 4.730181966935556), ('united', 4.670886025579755), ('development', 4.486058782622221), ('countries', 4.133976167378458), ('sides', 4.1036679228519715)]\n",
      "\n",
      "Top ten words used in USA-Canada relations by USA (TF-IDF):\n",
      "[('rubio', 2.4429236516796022), ('secretary', 2.299747000856435), ('canada', 1.716387707080005), ('president', 1.4242711553828786), ('united', 1.398209275889897), ('bruce', 1.279708607556207), ('trump', 1.2795782249181216), ('question', 1.2421487565967222), ('state', 1.2385139181563596), ('states', 1.2340531792207166)]\n",
      "\n",
      "Top ten words used in USA-Canada relations by Canada (TF-IDF):\n",
      "[('canada', 8.61391394590454), ('minister', 5.444366133922916), ('trade', 5.4263163561121965), ('united', 5.211814419219039), ('states', 4.760708013774341), ('media', 3.393656338696044), ('ng', 3.350832143630253), ('economic', 3.3239078558371165), ('international', 3.03407310960004), ('arctic', 2.970901967503062)]\n",
      "\n",
      "Top ten words used in China-Canada relations by China (TF-IDF):\n",
      "[('relations', 0.9747857019180075), ('china', 0.6872923006534755), ('canada', 0.5196863556845177), ('sides', 0.5189716189208493), ('foreign', 0.48582419317605297), ('cooperation', 0.470861214386076), ('countries', 0.46183202273490664), ('yi', 0.4111211711343321), ('wang', 0.3983076678206391), ('chinese', 0.3131628505845918)]\n",
      "\n",
      "Top ten words used in China-Canada relations by Canada (TF-IDF):\n",
      "[('tribunal', 10.131452222141016), ('dumping', 5.281659494673877), ('government', 4.970182359568081), ('injury', 4.507049616686656), ('trade', 4.4843290856021225), ('canada', 4.461537442341019), ('complaints', 4.271519996554061), ('federal', 4.271519996554061), ('expiry', 4.0865569172642635), ('subsidizing', 4.046351446604259)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenizer and remove filler/stop words and non alphabetic characters\n",
    "from spacy.lang.en import English\n",
    "en = English()\n",
    "n = 10 #top 10 words\n",
    "\n",
    "def simple_tokenizer(doc, model=en):\n",
    "    tokenized_docs = []\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.like_url)&(not t.is_stop)])\n",
    "\n",
    "#TF-IDF Vectorization with unigrams\n",
    "tfidf_text_content = TfidfVectorizer(tokenizer = simple_tokenizer, token_pattern = None, ngram_range=(1,1))\n",
    "\n",
    "\n",
    "#USA and China\n",
    "tfidf_text_content_vecs = tfidf_text_content.fit_transform(usa_china_df['Content']).toarray()\n",
    "#returns filter names identified by TF-IDF vectorizer\n",
    "#filter so that the source is USA articles, sum by column over all USA documents\n",
    "#creates dictionary for top words and their TF-IDF score\n",
    "tfidf_count_text_content_usa_to_china = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[usa_china_df['Source'] == 'USA'].sum(axis = 0)))\n",
    "print('Top ten words used in USA-China relations by USA (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_usa_to_china.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "tfidf_count_text_content_china_to_usa = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[usa_china_df['Source'] == 'China'].sum(axis = 0)))\n",
    "print('Top ten words used in USA-China relations by China (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_china_to_usa.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "#USA and Canada\n",
    "tfidf_text_content_vecs = tfidf_text_content.fit_transform(usa_canada_df['Content']).toarray()\n",
    "tfidf_count_text_content_usa_to_canada = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[usa_canada_df['Source'] == 'USA'].sum(axis = 0)))\n",
    "print('Top ten words used in USA-Canada relations by USA (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_usa_to_canada.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "tfidf_count_text_content_canada_to_usa = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[usa_canada_df['Source'] == 'Canada'].sum(axis = 0)))\n",
    "print('Top ten words used in USA-Canada relations by Canada (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_canada_to_usa.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "#China and Canada\n",
    "tfidf_text_content_vecs = tfidf_text_content.fit_transform(china_canada_df['Content']).toarray()\n",
    "tfidf_count_text_content_china_to_canada = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[china_canada_df['Source'] == 'China'].sum(axis = 0)))\n",
    "print('Top ten words used in China-Canada relations by China (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_china_to_canada.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "tfidf_count_text_content_canada_to_china = dict(zip(tfidf_text_content.get_feature_names_out(), tfidf_text_content_vecs[china_canada_df['Source'] == 'Canada'].sum(axis = 0)))\n",
    "print('Top ten words used in China-Canada relations by Canada (TF-IDF):')\n",
    "print(sorted(tfidf_count_text_content_canada_to_china.items(), key=lambda x: x[1], reverse=True)[:n], end='\\n\\n')\n",
    "\n",
    "#save dictionaries in an overall dictionary\n",
    "tfidf_dicts = {'USA-China': tfidf_count_text_content_usa_to_china,\n",
    "              'China-USA': tfidf_count_text_content_china_to_usa,\n",
    "              'USA-Canada': tfidf_count_text_content_usa_to_canada,\n",
    "              'Canada-USA': tfidf_count_text_content_canada_to_usa,\n",
    "              'China-Canada': tfidf_count_text_content_china_to_canada,\n",
    "              'Canada-China': tfidf_count_text_content_canada_to_china}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1f3894-20ce-4928-9338-0c33b1e0c2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One way sentiment scores:\n",
      "{'USA-China': 0.0018955109500511363, 'China-USA': 0.05272844829717349, 'USA-Canada': 0.009723402657518592, 'Canada-USA': 0.024411005915066442, 'China-Canada': 0.033428201803034026, 'Canada-China': -0.02094964408544498}\n",
      "\n",
      "Bilateral sentiment scores (NLTK):\n",
      "{'USA-China': 0.027311979623612315, 'USA-Canada': 0.017067204286292516, 'China-Canada': 0.0062392788587945225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/matthewhirokawa/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Get sentiment of words from dictionaries\n",
    "#Use opinion lexicon from NLTK, Natural Language Toolkit, identifies words as positive or negative\n",
    "\n",
    "#potential issues: all are weighted the same, no difference between very negative/slightly negative, etc.\n",
    "\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon')\n",
    "\n",
    "#get words that are positive or negative\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "'''\n",
    "#identify whether words in a dictionary are marked positive or negative\n",
    "def label_sentiment_words(tfidf_dict):\n",
    "    sentiment_labels = {}\n",
    "    for word in tfidf_dict:\n",
    "        if word in positive_words:\n",
    "            sentiment_labels[word] = \"positive\"\n",
    "        elif word in negative_words:\n",
    "            sentiment_labels[word] = \"negative\"\n",
    "        else:\n",
    "            sentiment_labels[word] = \"neutral\"\n",
    "    return sentiment_labels\n",
    "\n",
    "#stores dictionaries of the words identified as positive, negative, or neutral\n",
    "sentiment_labels = {}\n",
    "\n",
    "for relation, tfidf_dict in tfidf_dicts.items():\n",
    "    label = label_sentiment_words(tfidf_dict)\n",
    "    sentiment_labels[relation] = label\n",
    "\n",
    "print(sentiment_labels)\n",
    "'''\n",
    "\n",
    "#pass in TF-IDF dictionaries and calculate overall sentiment\n",
    "#returns between -1 and 1, negative to positive\n",
    "def compute_overall_sentiment(tfidf_dict):\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "    for word, tfidf_score in tfidf_dict.items():\n",
    "        if word in positive_words:\n",
    "            sentiment = 1  #positive\n",
    "        elif word in negative_words:\n",
    "            sentiment = -1  #negative\n",
    "        else:\n",
    "            sentiment = 0  #unknown\n",
    "\n",
    "        total_score += tfidf_score * sentiment\n",
    "        total_weight += tfidf_score\n",
    "\n",
    "    overall_sentiment = total_score / total_weight\n",
    "    return overall_sentiment\n",
    "\n",
    "#get all sentiments\n",
    "#assign to new dictionary\n",
    "sentiment_scores = {}\n",
    "\n",
    "for relation, tfidf_dict in tfidf_dicts.items():\n",
    "    sentiment = compute_overall_sentiment(tfidf_dict)\n",
    "    sentiment_scores[relation] = sentiment\n",
    "\n",
    "print('One way sentiment scores:')\n",
    "print(sentiment_scores)\n",
    "\n",
    "#get overall bilateral sentiment\n",
    "pairs_to_combine = [('USA-China', 'China-USA'), ('USA-Canada', 'Canada-USA'), ('China-Canada', 'Canada-China')]\n",
    "bilateral_sentiment_scores_nltk = {}\n",
    "\n",
    "for country_a, country_b in pairs_to_combine:\n",
    "    #pass in country relationship, e.g. USA-China for country_a, call function to compute one way sentiment on dictionary\n",
    "    #that corresponds to country_a, e.g. call on key USA-China\n",
    "    score_a = compute_overall_sentiment(tfidf_dicts[country_a])\n",
    "    score_b = compute_overall_sentiment(tfidf_dicts[country_b])\n",
    "    \n",
    "    combined_score = (score_a + score_b) / 2\n",
    "    \n",
    "    #relation_name = f\"{country_a.split('-')[0]}-{country_a.split('-')[1]}\"\n",
    "    relation_name = country_a\n",
    "    bilateral_sentiment_scores_nltk[relation_name] = combined_score\n",
    "\n",
    "print('')\n",
    "print('Bilateral sentiment scores (NLTK):')\n",
    "print(bilateral_sentiment_scores_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e8fedb-5374-40c1-9185-1069a2e2a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilateral sentiment scores (TextBlob):\n",
      "{'USA-China': 0.012354003880755887, 'USA-Canada': 0.006907417384210383, 'China-Canada': 0.009433371859024544}\n"
     ]
    }
   ],
   "source": [
    "#robustness check on sentiment value by using TextBlob instead of NLTK \n",
    "#TextBlob handles extremity of words, more negative for more hostile, more positive for more friendly\n",
    "#NLTK only assigns -1, 0, 1\n",
    "#TextBlob has larger vocabulary\n",
    "from textblob import TextBlob\n",
    "\n",
    "#adjust previously defined function to use TextBlob\n",
    "def compute_overall_sentiment_textblob(tfidf_dict):\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "    for word, tfidf_score in tfidf_dict.items():\n",
    "        \n",
    "        #get sentimentfor the single word and weight by TF-IDF value\n",
    "        sentiment = TextBlob(word).sentiment.polarity\n",
    "        \n",
    "        total_score += tfidf_score * sentiment\n",
    "        total_weight += tfidf_score\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        return 0  # or np.nan if you prefer\n",
    "    \n",
    "    overall_sentiment = total_score / total_weight\n",
    "    return overall_sentiment\n",
    "\n",
    "bilateral_sentiment_scores_textblob = {}\n",
    "\n",
    "for country_a, country_b in pairs_to_combine:\n",
    "    #pass in country relationship, e.g. USA-China for country_a, call function to compute one way sentiment on dictionary\n",
    "    #that corresponds to country_a, e.g. call on key USA-China\n",
    "    score_a = compute_overall_sentiment_textblob(tfidf_dicts[country_a])\n",
    "    score_b = compute_overall_sentiment_textblob(tfidf_dicts[country_b])\n",
    "    \n",
    "    combined_score = (score_a + score_b) / 2\n",
    "    \n",
    "    #relation_name = f\"{country_a.split('-')[0]}-{country_a.split('-')[1]}\"\n",
    "    relation_name = country_a\n",
    "    bilateral_sentiment_scores_textblob[relation_name] = combined_score\n",
    "\n",
    "print('Bilateral sentiment scores (TextBlob):')\n",
    "print(bilateral_sentiment_scores_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f875bd-a695-48f9-8709-3af53c45dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get monthly tfidf values for each country relationship (one way)\n",
    "def compute_monthly_tfidf_dict(df, tokenizer):\n",
    "    monthly_tfidf = {}\n",
    "    for month, group in df.groupby('Month'):\n",
    "        #drop NaNs, grouped by month\n",
    "        texts = group['Content'].dropna().tolist()\n",
    "        if not texts:\n",
    "            continue\n",
    "\n",
    "        #use tf-idf vectorizer\n",
    "        vectorizer = TfidfVectorizer(tokenizer = simple_tokenizer, token_pattern = None, ngram_range=(1,1))\n",
    "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()   #get words\n",
    "        tfidf_sum = tfidf_matrix.sum(axis=0)   #sum across all documents per month\n",
    "\n",
    "        #create dictionary to store words and their tf-idf values\n",
    "        tfidf_dict = {feature_names[i]: tfidf_sum[0, i] for i in range(len(feature_names))}\n",
    "        monthly_tfidf[month] = tfidf_dict\n",
    "    return monthly_tfidf\n",
    "\n",
    "#compute monthly tfidf values\n",
    "usa_china_tfidf = compute_monthly_tfidf_dict(usa_china_df, simple_tokenizer)\n",
    "china_usa_tfidf = compute_monthly_tfidf_dict(usa_china_df, simple_tokenizer)\n",
    "usa_canada_tfidf = compute_monthly_tfidf_dict(usa_canada_df, simple_tokenizer)\n",
    "canada_usa_tfidf = compute_monthly_tfidf_dict(usa_canada_df, simple_tokenizer)\n",
    "china_canada_tfidf = compute_monthly_tfidf_dict(china_canada_df, simple_tokenizer)\n",
    "canada_china_tfidf = compute_monthly_tfidf_dict(china_canada_df, simple_tokenizer)\n",
    "\n",
    "relations = [('USA-China', usa_china_tfidf, china_usa_tfidf),\n",
    "             ('USA-Canada', usa_canada_tfidf, canada_usa_tfidf),\n",
    "             ('China-Canada', china_canada_tfidf, canada_china_tfidf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae52adb-fe74-49c3-b0e5-ec262fbe8563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly sentiment (NLTK):\n",
      "      Month      Relation  Sentiment\n",
      "0   2024-01  China-Canada  -0.032424\n",
      "1   2024-01    USA-Canada   0.007185\n",
      "2   2024-01     USA-China   0.071273\n",
      "3   2024-02  China-Canada  -0.008471\n",
      "4   2024-02    USA-Canada   0.006222\n",
      "5   2024-02     USA-China   0.046718\n",
      "6   2024-03  China-Canada  -0.049284\n",
      "7   2024-03    USA-Canada   0.064931\n",
      "8   2024-03     USA-China   0.079513\n",
      "9   2024-04  China-Canada  -0.014640\n",
      "10  2024-04    USA-Canada   0.048664\n",
      "11  2024-04     USA-China   0.006797\n",
      "12  2024-05  China-Canada   0.020213\n",
      "13  2024-05    USA-Canada   0.028783\n",
      "14  2024-05     USA-China   0.023514\n",
      "15  2024-06  China-Canada  -0.022357\n",
      "16  2024-06    USA-Canada   0.000000\n",
      "17  2024-06     USA-China   0.012443\n",
      "18  2024-07  China-Canada  -0.006569\n",
      "19  2024-07    USA-Canada   0.012919\n",
      "20  2024-07     USA-China   0.045415\n",
      "21  2024-08  China-Canada  -0.042158\n",
      "22  2024-08    USA-Canada   0.040612\n",
      "23  2024-08     USA-China   0.035218\n",
      "24  2024-09  China-Canada  -0.042958\n",
      "25  2024-09    USA-Canada   0.030959\n",
      "26  2024-09     USA-China   0.051888\n",
      "27  2024-10  China-Canada  -0.070588\n",
      "28  2024-10    USA-Canada   0.009656\n",
      "29  2024-10     USA-China   0.046902\n",
      "30  2024-11  China-Canada   0.015320\n",
      "31  2024-11    USA-Canada   0.041989\n",
      "32  2024-11     USA-China   0.097110\n",
      "33  2024-12  China-Canada  -0.031289\n",
      "34  2024-12    USA-Canada   0.001042\n",
      "35  2024-12     USA-China   0.063236\n",
      "36  2025-01  China-Canada   0.066667\n",
      "37  2025-01    USA-Canada   0.029099\n",
      "38  2025-01     USA-China   0.033864\n",
      "39  2025-02  China-Canada  -0.070777\n",
      "40  2025-02    USA-Canada   0.037701\n",
      "41  2025-02     USA-China   0.036259\n",
      "42  2025-03  China-Canada  -0.029669\n",
      "43  2025-03    USA-Canada   0.004502\n",
      "44  2025-03     USA-China  -0.006772\n",
      "45  2025-04  China-Canada  -0.044488\n",
      "46  2025-04    USA-Canada   0.011314\n",
      "47  2025-04     USA-China  -0.006127\n",
      "48  2025-05  China-Canada  -0.033453\n",
      "49  2025-05    USA-Canada   0.014695\n",
      "50  2025-05     USA-China   0.039569\n",
      "51  2025-06  China-Canada  -0.054890\n",
      "52  2025-06    USA-Canada   0.004504\n",
      "53  2025-06     USA-China   0.047488\n",
      "54  2025-07  China-Canada  -0.005082\n",
      "55  2025-07    USA-Canada   0.122304\n",
      "56  2025-07     USA-China   0.051961\n",
      "\n",
      "Monthly sentiment (Textblob):\n",
      "      Month      Relation  Sentiment\n",
      "0   2024-01  China-Canada   0.003673\n",
      "1   2024-01    USA-Canada   0.008041\n",
      "2   2024-01     USA-China   0.018102\n",
      "3   2024-02  China-Canada   0.005115\n",
      "4   2024-02    USA-Canada   0.005889\n",
      "5   2024-02     USA-China   0.022177\n",
      "6   2024-03  China-Canada   0.001831\n",
      "7   2024-03    USA-Canada   0.016219\n",
      "8   2024-03     USA-China   0.022824\n",
      "9   2024-04  China-Canada   0.003440\n",
      "10  2024-04    USA-Canada   0.010289\n",
      "11  2024-04     USA-China   0.013694\n",
      "12  2024-05  China-Canada   0.008569\n",
      "13  2024-05    USA-Canada   0.010093\n",
      "14  2024-05     USA-China   0.013158\n",
      "15  2024-06  China-Canada   0.005292\n",
      "16  2024-06    USA-Canada   0.001563\n",
      "17  2024-06     USA-China   0.007207\n",
      "18  2024-07  China-Canada   0.005790\n",
      "19  2024-07    USA-Canada   0.006272\n",
      "20  2024-07     USA-China   0.016490\n",
      "21  2024-08  China-Canada   0.001923\n",
      "22  2024-08    USA-Canada   0.016344\n",
      "23  2024-08     USA-China   0.009777\n",
      "24  2024-09  China-Canada   0.001843\n",
      "25  2024-09    USA-Canada   0.005339\n",
      "26  2024-09     USA-China   0.018727\n",
      "27  2024-10  China-Canada   0.004874\n",
      "28  2024-10    USA-Canada   0.004192\n",
      "29  2024-10     USA-China   0.010123\n",
      "30  2024-11  China-Canada   0.010065\n",
      "31  2024-11    USA-Canada   0.012531\n",
      "32  2024-11     USA-China   0.019682\n",
      "33  2024-12  China-Canada   0.010421\n",
      "34  2024-12    USA-Canada  -0.000287\n",
      "35  2024-12     USA-China   0.016515\n",
      "36  2025-01  China-Canada   0.021929\n",
      "37  2025-01    USA-Canada   0.006963\n",
      "38  2025-01     USA-China   0.014288\n",
      "39  2025-02  China-Canada  -0.000835\n",
      "40  2025-02    USA-Canada   0.009817\n",
      "41  2025-02     USA-China   0.012910\n",
      "42  2025-03  China-Canada   0.001291\n",
      "43  2025-03    USA-Canada   0.007619\n",
      "44  2025-03     USA-China   0.010101\n",
      "45  2025-04  China-Canada   0.001299\n",
      "46  2025-04    USA-Canada   0.004782\n",
      "47  2025-04     USA-China   0.002519\n",
      "48  2025-05  China-Canada   0.007396\n",
      "49  2025-05    USA-Canada   0.007976\n",
      "50  2025-05     USA-China   0.010292\n",
      "51  2025-06  China-Canada   0.005486\n",
      "52  2025-06    USA-Canada   0.009382\n",
      "53  2025-06     USA-China   0.016454\n",
      "54  2025-07  China-Canada   0.006280\n",
      "55  2025-07    USA-Canada   0.014520\n",
      "56  2025-07     USA-China   0.019876\n"
     ]
    }
   ],
   "source": [
    "#get monthly bilateral sentiment\n",
    "monthly_bilateral_sentiment_nltk = defaultdict(dict)  # {month: {pair_name: score}}\n",
    "\n",
    "for pair_name, tfidf_a, tfidf_b in relations:\n",
    "    all_months = set(tfidf_a.keys()).union(set(tfidf_b.keys()))\n",
    "\n",
    "    #compute sentiment by month, convert to bilateral sentiment by averaging\n",
    "    for month in sorted(all_months):\n",
    "        dict_a = tfidf_a.get(month)\n",
    "        dict_b = tfidf_b.get(month)\n",
    "\n",
    "        score_a = compute_overall_sentiment(dict_a) if dict_a else None\n",
    "        score_b = compute_overall_sentiment(dict_b) if dict_b else None\n",
    "\n",
    "        #checks case where one way sentiment does not exist for a country\n",
    "        if score_a is not None and score_b is not None:\n",
    "            combined_score = (score_a + score_b) / 2\n",
    "        elif score_a is not None:\n",
    "            combined_score = score_a\n",
    "        elif score_b is not None:\n",
    "            combined_score = score_b\n",
    "        else:\n",
    "            continue  # no data\n",
    "\n",
    "        monthly_bilateral_sentiment_nltk[month][pair_name] = combined_score\n",
    "\n",
    "#save as csv\n",
    "rows = []\n",
    "#loop on each month and dictionary of relations and monthly tf-idf value\n",
    "for month, scores_dict in monthly_bilateral_sentiment_nltk.items():\n",
    "    #loop on relation and get score for month\n",
    "    for pair, score in scores_dict.items():\n",
    "        rows.append({'Month': month, 'Relation': pair, 'Sentiment': score})\n",
    "\n",
    "monthly_sentiment_df_nltk = pd.DataFrame(rows)\n",
    "monthly_sentiment_df_nltk = monthly_sentiment_df_nltk.sort_values(['Month', 'Relation']).reset_index(drop = True)\n",
    "print('Monthly sentiment (NLTK):')\n",
    "print(monthly_sentiment_df_nltk)\n",
    "print('')\n",
    "monthly_sentiment_df_nltk.to_csv(\"monthly_sentiment_nltk.csv\", index = False)\n",
    "\n",
    "\n",
    "#monthly bilateral sentiment with TextBlob\n",
    "monthly_bilateral_sentiment_textblob = defaultdict(dict)  # {month: {pair_name: score}}\n",
    "#get monthly bilateral sentiment\n",
    "for pair_name, tfidf_a, tfidf_b in relations:\n",
    "    all_months = set(tfidf_a.keys()).union(set(tfidf_b.keys()))\n",
    "\n",
    "    #compute sentiment by month, convert to bilateral sentiment by averaging\n",
    "    for month in sorted(all_months):\n",
    "        dict_a = tfidf_a.get(month)\n",
    "        dict_b = tfidf_b.get(month)\n",
    "\n",
    "        score_a = compute_overall_sentiment_textblob(dict_a) if dict_a else None\n",
    "        score_b = compute_overall_sentiment_textblob(dict_b) if dict_b else None\n",
    "\n",
    "        #checks case where one way sentiment does not exist for a country\n",
    "        if score_a is not None and score_b is not None:\n",
    "            combined_score = (score_a + score_b) / 2\n",
    "        elif score_a is not None:\n",
    "            combined_score = score_a\n",
    "        elif score_b is not None:\n",
    "            combined_score = score_b\n",
    "        else:\n",
    "            continue  # no data\n",
    "\n",
    "        monthly_bilateral_sentiment_textblob[month][pair_name] = combined_score\n",
    "\n",
    "#save as csv\n",
    "rows = []\n",
    "#loop on each month and dictionary of relations and monthly tf-idf value\n",
    "for month, scores_dict in monthly_bilateral_sentiment_textblob.items():\n",
    "    #loop on relation and get score for month\n",
    "    for pair, score in scores_dict.items():\n",
    "        rows.append({'Month': month, 'Relation': pair, 'Sentiment': score})\n",
    "\n",
    "monthly_sentiment_df_textblob = pd.DataFrame(rows)\n",
    "monthly_sentiment_df_textblob = monthly_sentiment_df_textblob.sort_values(['Month', 'Relation']).reset_index(drop = True)\n",
    "print('Monthly sentiment (Textblob):')\n",
    "print(monthly_sentiment_df_textblob)\n",
    "monthly_sentiment_df_textblob.to_csv(\"monthly_sentiment_textblob.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
